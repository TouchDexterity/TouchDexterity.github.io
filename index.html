<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Rotating without Seeing: Towards In-hand Dexterity through Touch">
  <meta name="keywords" content="Dexterous Manipulation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>
    Rotating without Seeing
  </title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css"
  integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
    integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
    crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.14.7/dist/umd/popper.min.js"
    integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1"
    crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/js/bootstrap.min.js"
    integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM"
    crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <style>
    .videoWrapper {
      position: relative;
      padding-bottom: 56.25%;
      /* 16:9 */
      height: 0;
    }
    
    .videoWrapper iframe {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
    }
  </style>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">
            Rotating without Seeing:  <br> Towards In-hand Dexterity through Touch</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a target="_blank" href="https://zhaohengyin.github.io/">Zhao-Heng&#160;Yin</a><sup>1,&dagger;</sup>,
              <a target="_blank" href="https://binghao-huang.github.io/">Binghao&#160;Huang</a><sup>2,&dagger;</sup>,
              <a target="_blank" href="https://yzqin.github.io/">Yuzhe&#160;Qin</a><sup>2</sup>,
              <a target="_blank" href="https://cqf.io/">Qifeng&#160;Chen</a><sup>1</sup>,
              <a target="_blank" href="https://xiaolonw.github.io/">Xiaolong&#160;Wang</a><sup>2</sup>
          </span>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>HKUST</span> &nbsp;
            <span class="author-block"><sup>2</sup>UC San Diego </span>
            <br>
            <span class="author-block"><sup>&dagger;</sup>Equal Contribution. </span>
        </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="columns is-centered has-text-centered">
    <div class="container is-max-desktop">
      <h2 class="title is-3"> Video Summary </h2>
          <div class="content has-text-justified">
            <div class="columns is-centered interpolation-panel" style="background: #FDFFFF;">
              <div class="column has-text-centered">
                <!-- <video controls width="100%">
                  <source src="video/summary_video.mp4" type="video/mp4"/>
                </video> -->
                <div class="videoWrapper">
                <iframe src="https://www.youtube.com/embed/TGOB_6ZSc2s" title="YouTube video player" 
                frameborder="0" allow="accelerometer; autoplay; 
                clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>
                </iframe>
                </div>

              </div>
            </div>
          </div>
    
      <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="video/web_12video_title.mov" type="video/mp4"/>
      </video> -->
      <!-- <p style="font-size: 18px; text-align: center">
        We present a new dexterous manipulation system design and learning pipeline for in-hand rotation using only touch. Our system is able to rotate various real-world objects around different axes without seeing them. Video speed is 1x.
      </p> -->
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">

        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p style="font-size: 18px; text-align: left">
            Tactile information plays a critical role in human dexterity. 
            It reveals useful contact information that may not be inferred directly from vision. 
            In fact, humans can even perform in-hand dexterous manipulation without using vision. 
            Can we enable the same ability for the multi-finger robot hand? 
            In this paper, we propose to perform in-hand object rotation using only touching without seeing the object. 
            Instead of relying on precise tactile sensing in a small region, 
            we introduce a new system design using dense binary force sensors (touch or no touch) overlaying one side of the whole robot hand (palm, finger links, fingertips). 
            Such a design is low-cost, giving a larger coverage of the object, and minimizing the Sim2Real gap at the same time.
            We train an in-hand rotation policy using Reinforcement Learning on diverse objects in simulation. 
            Relying on touch-only sensing, we can directly deploy the policy in a real robot hand and rotate novel objects that are not presented in training. 
            Extensive ablations are performed on how tactile information help in-hand manipulation. 
          </p>
          <br>
          <br>
        </div>
        
        <h2 class="title is-3">Touch-only Dexterous Manipulation System</h2>
        <div class="content has-text-justified">
          <p style="font-size: 18px; text-align: left">
            We present a new dexterous manipulation system design and learning pipeline for in-hand rotation using only touch. 
            Our system is able to rotate various real-world objects around different axes without seeing them.
            The hardware is consisted of an Allegro robotic hand with 16 low-cost force-sensing resistor (FSR) sensors. 
            We train a control policy to rotate multiple objects in the simulation through RL. 
            Then the learned policy can directly transfer to the real and generalize to unseen, novel objects.
          </p>
          <br>
          <br>
          <div class="columns is-centered" style="background: #FDFFFF;">
            <img src="./static/images/teaser.png" alt="teaser">
          </div>
          <br>
        </div>

        <h2 class="title is-3">In-hand Object Rotation In The Dark</h2>
        <p style="font-size: 18px; text-align: left">
        Since our system does not rely on vision, it can perform in-hand manipulation in the dark. 
        This offers great advantage for the application of dexterous manipulation system in complex real-world scenarios, where obtaining reliable visual input is hard.
        <br>
        <br>
        <p style="font-size: 18px; text-align: left">  
        <div class="content has-text-justified">
          <div class="columns is-centered interpolation-panel" style="background: #FDFFFF;">
            <div class="column has-text-centered">
              <video controls autoplay muted loop playsinline width="100%">
                <source src="video/web_light_demo.mp4" type="video/mp4"/>
              </video>
            </div>
          </div>
          <br>
        </div>
        <h2 class="title is-3">Rotating Different Objects</h2>
        <div class="container is-max-desktop">
          <div id="results-carousel-grasp" class="carousel results-carousel">
            <div class="item">
              <video poster="" id="x1" autoplay muted playsinline loop height="100%">
                <source src="video/items/x1.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item">
              <video poster="" id="x2" autoplay muted playsinline loop height="100%">
                <source src="video/items/x2.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item">
              <video poster="" id="x3" autoplay muted playsinline loop height="100%">
                <source src="video/items/x3.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item">
              <video poster="" id="x4" autoplay muted playsinline loop height="100%">
                <source src="video/items/x4.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item">
              <video poster="" id="y1" autoplay  muted playsinline loop height="100%">
                <source src="video/items/y1.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item">
              <video poster="" id="y2" autoplay  muted loop height="100%">
                <source src="video/items/y2.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item">
              <video poster="" id="y3" autoplay muted loop height="100%">
                <source src="video/items/y3.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item">
              <video poster="" id="y4" autoplay  muted loop height="100%">
                <source src="video/items/y4.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item">
              <video poster="" id="z1" autoplay  muted playsinline loop height="100%">
                <source src="video/items/z1.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item">
              <video poster="" id="z2" autoplay  muted loop height="100%">
                <source src="video/items/z2.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item">
              <video poster="" id="z3" autoplay muted loop height="100%">
                <source src="video/items/z3.mp4" type="video/mp4">
              </video>
            </div>
            <div class="item">
              <video poster="" id="z4" autoplay  muted loop height="100%">
                <source src="video/items/z4.mp4" type="video/mp4">
              </video>
            </div>

          </div>
          <br>
        </div>

        <h2 class="title is-3">Enabling Human-Shared Control</h2>
        <p style="font-size: 18px; text-align: left">
        Combining various learned object rotation primitives, our system naturally provides a convenient human-shared control interface. 
        In the following example, a human operator uses a keyboard to control our system to reorient an object.
        <br>
        <br>
        </p>  
        <div class="content has-text-justified">
          <div class="columns is-centered interpolation-panel" style="background: #FDFFFF;">
            <div class="column has-text-centered">
              <video controls autoplay muted loop playsinline width="100%">
                <source src="video/web_human_shared_control.mp4" type="video/mp4"/>
              </video>
            </div>
          </div>
          <br>
        </div>

        <h2 class="title is-3">Understanding Shapes through Touch</h2>
        <p style="font-size: 18px; text-align: left">
        To understand how touch information could be helpful, we conduct a study from a shape understanding perspective. 
        We train a neural network to predict the object's shape from the rotation rollout. 
        Then, we use it to predict a novel object's shape from its rotation rollout. 
        We find that reconstructing the object's shape accurately is possible only if the touch information presents in the rollout.
        <br>
        <br>
        </p> 
        <div class="content has-text-justified">
          <div class="columns is-centered interpolation-panel" style="background: #FDFFFF;">
            <div class="column has-text-centered">
              <video  controls  autoplay muted loop playsinline width="70%">
                <source src="video/web_recon.mp4" type="video/mp4"/>
              </video>
            </div>
          </div>
          <br>
        </div>

        <h2 class="title is-3">Conclusion</h2>
        <p style="font-size: 18px; text-align: left">
          We have presented a tactile manipulation system that is able to rotate different objects without vision. 
          We showed an end-to-end RL framework to learn tactile dexterity over the proposed system. 
          We carried out experiments both in simulation and real to demonstrate its effectiveness. 
          Our work demonstrated that we are able to achieve tactile dexterity as humans in real for the first time. 
          In the future, there are many promising future directions to investigate, such as exploring the use of a more dense contact sensor array and scaling up the system to solve more diverse tasks.
          We hope that our work can pave the way for more intelligent robot hands.
        <br>
        <br>
        </p> 

        
    </div>
  </div>
</section>

</body>
</html>
